{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4258e048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kilia\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\\torch\\csrc\\tensor\\python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.cuda.is_available()\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "import torch.jit as jit\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import os\n",
    "from scipy import io\n",
    "import pickle\n",
    "device='cpu'\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "from Util_Benchmarking import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "985aeaa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "T_data=1000\n",
    "Data=Data_Manager(\"MACKEY_manuscript\",T_data)\n",
    "\n",
    "S_first=Data.S\n",
    "Y_first=Data.Y\n",
    "\n",
    "Data.Init_ESN(N=500, N_in=1, N_av=10, alpha=0.9, rho=0.99, gamma=0.15)\n",
    "\n",
    "Data.ESN_Process()\n",
    "\n",
    "X_esn=Data.X\n",
    "\n",
    "\n",
    "Data.ESN=False\n",
    "T_seg=10\n",
    "\n",
    "Data.Segmentation(T_seg)\n",
    "\n",
    "S_seg=Data.S\n",
    "Y_seg=Data.Y\n",
    "\n",
    "val_prc=0.1\n",
    "Data.Splitting(val_prc)\n",
    "\n",
    "S_tr=Data.S_tr\n",
    "S_val=Data.S_val\n",
    "S_te=Data.S_te\n",
    "\n",
    "Y_tr=Data.Y_tr\n",
    "Y_val=Data.Y_val\n",
    "Y_te=Data.Y_te\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2,figsize=(20,10))\n",
    "\n",
    "N_y=3\n",
    "T_plot=100\n",
    "\n",
    "axs[0,0].plot(S_first[0:T_plot,:].to('cpu'),'black')\n",
    "\n",
    "N_y=3\n",
    "for n in range(1,N_y):\n",
    "    axs[0,0].plot(Y_first[0:T_plot,n].to('cpu'),'red')\n",
    "    \n",
    "axs[0,0].set(xlabel='Step number',ylabel='Signal and Targets')\n",
    "\n",
    "\n",
    "axs[0,1].plot(S_first[0:T_plot,:].to('cpu'), color='black', linestyle='dashed')\n",
    "\n",
    "N_esn=100\n",
    "cl=cm.inferno(np.linspace(0,1,N_esn))\n",
    "\n",
    "for n in range(1,N_esn):\n",
    "    axs[0,1].plot(X_esn[0:T_plot,n].to('cpu'),color=cl[n,:])\n",
    "    \n",
    "axs[0,1].set(xlabel='Step number',ylabel='Signal and ESN response')\n",
    "\n",
    "for n in range(T_seg):\n",
    "    axs[1,0].plot(S_seg[0:T_plot,n].to('cpu'),'black')\n",
    "\n",
    "N_y=2\n",
    "for n in range(1,N_y):\n",
    "    axs[1,0].plot(Y_seg[0:T_plot,n].to('cpu'),'red')\n",
    "    \n",
    "axs[1,0].set(xlabel='Step number',ylabel='Signal and Targets')\n",
    "\n",
    "\n",
    "\n",
    "ts_tr=torch.arange(0,S_tr.size()[0])\n",
    "ts_val=torch.arange(S_tr.size()[0],S_tr.size()[0]+S_val.size()[0])\n",
    "ts_te=torch.arange(S_tr.size()[0]+S_val.size()[0],S_tr.size()[0]+S_val.size()[0]+S_te.size()[0])\n",
    "\n",
    "T_tr_plot=100\n",
    "axs[1,1].plot(ts_tr[-T_tr_plot:].to('cpu'),S_tr.to('cpu')[-T_tr_plot:,-1],color='black')\n",
    "axs[1,1].plot(ts_val.to('cpu'),S_val.to('cpu')[:,-1],'black',linestyle='dashed')\n",
    "axs[1,1].plot(ts_te.to('cpu'),S_te.to('cpu')[:,-1],'black',linestyle='dashdot')\n",
    "\n",
    "axs[1,1].plot(ts_tr[-T_tr_plot:].to('cpu'),Y_tr.to('cpu')[-T_tr_plot:,2],color='red')\n",
    "axs[1,1].plot(ts_val.to('cpu'),Y_val.to('cpu')[:,2],linestyle='dashed',color='red')\n",
    "axs[1,1].plot(ts_te.to('cpu'),Y_te.to('cpu')[:,2],linestyle='dashdot',color='red')\n",
    "\n",
    "axs[1,1].set(xlabel='Step number',ylabel='Splitting')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_data=10000\n",
    "Data=Data_Manager(\"MACKEY\",T_data)\n",
    "\n",
    "\n",
    "Model_Id='MLP'\n",
    "val_prc=0.1\n",
    "\n",
    "if Model_Id=='ESN':\n",
    "    \n",
    "    N_ESN=500\n",
    "    N_in=1\n",
    "    N_av=10\n",
    "    alpha=0.9\n",
    "    rho=0.99\n",
    "    gamma=0.15\n",
    "    \n",
    "    Data.Init_ESN(N_ESN, N_in, N_av, alpha, rho, gamma)\n",
    "    Data.ESN_Process()\n",
    "    Data.Splitting(val_prc)\n",
    "    \n",
    "    F_Ns=torch.tensor([N_ESN,Data.Y_tr.size()[1]])\n",
    "    \n",
    "    eta=0.0001\n",
    "    weight_decay=0\n",
    "    model=Model_Learning(F_Ns, eta, weight_decay)\n",
    "    \n",
    "    T_seq=1\n",
    "    \n",
    "if Model_Id=='MLP':\n",
    "    \n",
    "    T_seg=5\n",
    "    Data.Segmentation(T_seg)\n",
    "    Data.Splitting(val_prc)\n",
    "\n",
    "    F_Ns=torch.tensor([Data.S_tr.size()[1],200,200,Y_tr.size()[1]])\n",
    "    \n",
    "    eta=0.001\n",
    "    weight_decay=0\n",
    "    model=Model_Learning(F_Ns, eta, weight_decay)\n",
    "    \n",
    "    T_seq=1\n",
    "    \n",
    "if Model_Id=='N_ODE':\n",
    "    \n",
    "    N_ODE=True\n",
    "    \n",
    "    T_seg=5\n",
    "    Data.Segmentation(T_seg)\n",
    "    Data.Splitting(val_prc)\n",
    "\n",
    "    \n",
    "    F_Ns=torch.tensor([Data.S_tr.size()[1],200,200,Data.S_tr.size()[1]])\n",
    "    \n",
    "    eta=0.001\n",
    "    weight_decay=0\n",
    "    model=Model_Learning(F_Ns, eta, weight_decay, N_ODE)\n",
    "    \n",
    "    T_seq=20\n",
    "    \n",
    "batch_size=20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train=20000\n",
    "N_checkpoint=500\n",
    "\n",
    "N_check=int(np.ceil(N_train/N_checkpoint))\n",
    "ind_help=0\n",
    "\n",
    "N_chunks=1\n",
    "\n",
    "MSE_Train=torch.zeros([N_train])\n",
    "\n",
    "MSE_Tr=torch.zeros([N_check])\n",
    "MSE_Val=torch.zeros([N_check])\n",
    "MSE_Te=torch.zeros([N_check])\n",
    "\n",
    "t0s=torch.tensor(0.)\n",
    "\n",
    "\n",
    "for k in range(N_train):\n",
    "    \n",
    "    X_b, Y_b=Data.Batch(batch_size, T_seq)\n",
    "    \n",
    "    if model.N_ODE:\n",
    "\n",
    "        var_help=X_b.clone()\n",
    "        X_b=var_help[:,:,0:-1].clone()\n",
    "        Y_b=var_help[:,:,1:]\n",
    "    \n",
    "    err,_=model.forward(X_b,Y_b,t0s)\n",
    "    MSE_Train[k]=err.detach()\n",
    "    \n",
    "    if k%N_checkpoint==0: \n",
    "        \n",
    "        \n",
    "        if k>0:\n",
    "            \n",
    "            mse_mean=torch.mean(MSE_Train[k-N_checkpoint:k])\n",
    "        \n",
    "            MSE_Tr[ind_help]=mse_mean\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            MSE_Tr[ind_help]=MSE_Train[k]\n",
    "            \n",
    "        \n",
    "        ## VALIDATING ##\n",
    "        #############\n",
    "                            \n",
    "        X_b,Y_b=Data.Testing()\n",
    "        \n",
    "        if model.N_ODE:\n",
    "            \n",
    "            var_help=X_b.clone()\n",
    "            X_b=var_help[:,:,0:-1].clone()\n",
    "            Y_b=var_help[:,:,1:]\n",
    "        \n",
    "        err_, y_=model.Seqforward(X_b,Y_b,t0s)\n",
    "        \n",
    "        MSE_Val[ind_help]=err_.detach()\n",
    "        \n",
    "        ## TESTING ##\n",
    "        #############\n",
    "        \n",
    "        X_b,Y_b=Data.Testing(False)\n",
    "        \n",
    "        if model.N_ODE:\n",
    "        \n",
    "            var_help=X_b.clone()\n",
    "            X_b=var_help[:,:,0:-1].clone()\n",
    "            Y_b=var_help[:,:,1:]\n",
    "        \n",
    "        err_, y_=model.Seqforward(X_b,Y_b,t0s)\n",
    "        \n",
    "        MSE_Te[ind_help]=err_.detach()\n",
    "        \n",
    "        print('Errors: ', MSE_Tr[ind_help], MSE_Val[ind_help] , MSE_Te[ind_help])\n",
    "        \n",
    "        ind_help=ind_help+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba08d61",
   "metadata": {},
   "source": [
    "Run the MLP comparison hyperparameters used in the manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe130e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "50 0 5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 58\u001b[0m\n\u001b[0;32m     53\u001b[0m t0s\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_train):\n\u001b[1;32m---> 58\u001b[0m     X_b, Y_b\u001b[38;5;241m=\u001b[39mData\u001b[38;5;241m.\u001b[39mBatch(batch_size, T_seq)\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mN_ODE:\n\u001b[0;32m     62\u001b[0m         var_help\u001b[38;5;241m=\u001b[39mX_b\u001b[38;5;241m.\u001b[39mclone()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "T_datax=[50,100,150,200,250,500,1000,2000]\n",
    "T_segx=[0,1,2,3,5,10,20]\n",
    "## Then number of nodes in the hidden layers, something like\n",
    "N_hiddenx=[5,10,20,40,60,80,100,150,200]  \n",
    "N_train=20000\n",
    "N_checkpoint=19999\n",
    "params = []\n",
    "for T_data in T_datax:\n",
    "    for T_seg in T_segx:\n",
    "        for N_hidden in N_hiddenx:\n",
    "            params.append([T_data,T_seg,N_hidden])\n",
    "print(len(params))\n",
    "import sys\n",
    "\n",
    "val_prc=0.1\n",
    "for i in range(len(params)):\n",
    "    param = params[i]\n",
    "    T_data=param[0]\n",
    "    T_seg = param[1]\n",
    "    N_hidden=param[2]\n",
    "\n",
    "    Data=Data_Manager(\"MACKEY_manuscript\",T_data)\n",
    "    \n",
    "\n",
    "    print(T_data,T_seg,N_hidden)\n",
    "\n",
    "    if T_seg>0:\n",
    "        Data.Segmentation(T_seg)\n",
    "\n",
    "    Data.Splitting(val_prc)\n",
    "    \n",
    "\n",
    "    F_Ns=torch.tensor([Data.S_tr.size()[1],N_hidden,N_hidden,Data.Y_tr.size()[1]])  ## Definition of the MLP shape\n",
    "\n",
    "    eta=0.001 ## Learning rate\n",
    "    weight_decay=0 ## Learning rate of the L2 penalty term \n",
    "    model=Model_Learning(F_Ns, eta, weight_decay)\n",
    "\n",
    "    T_seq=1\n",
    "    \n",
    "    \n",
    "    N_check=int(np.ceil(N_train/N_checkpoint))\n",
    "    ind_help=0\n",
    "\n",
    "    N_chunks=1\n",
    "\n",
    "    MSE_Train=torch.zeros([N_train])\n",
    "\n",
    "    MSE_Tr=torch.zeros([N_check])\n",
    "    MSE_Val=torch.zeros([N_check])\n",
    "    MSE_Te=torch.zeros([N_check])\n",
    "\n",
    "    t0s=torch.tensor(0.)\n",
    "\n",
    "    batch_size = 20\n",
    "    for k in range(N_train):\n",
    "\n",
    "        X_b, Y_b=Data.Batch(batch_size, T_seq)\n",
    "\n",
    "        if model.N_ODE:\n",
    "\n",
    "            var_help=X_b.clone()\n",
    "            X_b=var_help[:,:,0:-1].clone()\n",
    "            X_b=torch.concat([X_b,X_b],1)\n",
    "\n",
    "            Y_b=var_help[:,:,1:]\n",
    "\n",
    "        err,_=model.forward(X_b,Y_b,t0s)\n",
    "        MSE_Train[k]=err.detach()\n",
    "\n",
    "        if k%N_checkpoint==0: \n",
    "\n",
    "\n",
    "            if k>0:\n",
    "\n",
    "                mse_mean=torch.mean(MSE_Train[k-N_checkpoint:k])\n",
    "\n",
    "                MSE_Tr[ind_help]=mse_mean\n",
    "\n",
    "            else:\n",
    "\n",
    "                MSE_Tr[ind_help]=MSE_Train[k]\n",
    "\n",
    "\n",
    "            ## VALIDATING ##\n",
    "            #############\n",
    "\n",
    "            X_val,Y_val=Data.Testing()\n",
    "\n",
    "            if model.N_ODE:\n",
    "\n",
    "                var_help=X_val.clone()\n",
    "                X_val=var_help[:,:,0:-1].clone()\n",
    "                X_val=torch.concat([X_val,X_val],1)\n",
    "\n",
    "                Y_val=var_help[:,:,1:]\n",
    "\n",
    "            err_, y_val=model.Seqforward(X_val,Y_val,t0s)\n",
    "\n",
    "            MSE_Val[ind_help]=err_.detach()\n",
    "\n",
    "            ## TESTING ##\n",
    "            #############\n",
    "\n",
    "            X_te,Y_te=Data.Testing(False)\n",
    "\n",
    "            if model.N_ODE:\n",
    "\n",
    "                var_help=X_te.clone()\n",
    "                X_te=var_help[:,:,0:-1].clone()\n",
    "                X_te=torch.concat([X_te,X_te],1)\n",
    "\n",
    "                Y_te=var_help[:,:,1:]\n",
    "\n",
    "            err_, y_te=model.Seqforward(X_te,Y_te,t0s)\n",
    "\n",
    "            MSE_Te[ind_help]=err_.detach()\n",
    "\n",
    "            Nx_plot=3\n",
    "            Ny_plot=3\n",
    "\n",
    "            fig, axs = plt.subplots(Nx_plot, Ny_plot,figsize=(20,10))\n",
    "\n",
    "            print('Iteration number: ', k)\n",
    "            for l in range(Nx_plot):\n",
    "\n",
    "                for m in range(Ny_plot):\n",
    "\n",
    "                    t_pred=l*Nx_plot+m\n",
    "                    axs[l,m].plot(y_val.detach().to('cpu')[0,t_pred,:],'black')\n",
    "                    axs[l,m].plot(Y_val.detach().to('cpu')[0,t_pred,:],'red')\n",
    "\n",
    "                    axs[l,m].legend(['Prediction','Target'])\n",
    "                    #tit=\n",
    "                    axs[l,m].title.set_text('Delay: '+str(t_pred))\n",
    "\n",
    "\n",
    "            plt.savefig(os.path.join('MLP','Plots_T_data_{}_T_seg_{}_N_hidden_{}.png'.format(T_data,T_seg,N_hidden)))\n",
    "            #plt.show()\n",
    "            print('Errors: ', MSE_Tr[ind_help], MSE_Val[ind_help] , MSE_Te[ind_help])\n",
    "\n",
    "            ind_help=ind_help+1\n",
    "    #print(y_val)\n",
    "    print(y_te)\n",
    "    print(Y_te)\n",
    "    \n",
    "    torch.save(Y_te,os.path.join('MLP','xY_te_T_data_{}_T_seg_{}_N_hidden_{}.pt'.format(T_data,T_seg,N_hidden)))\n",
    "    torch.save(y_te,os.path.join('MLP','y_te_T_data_{}_T_seg_{}_N_hidden_{}.pt'.format(T_data,T_seg,N_hidden)))\n",
    "    torch.save(Y_val,os.path.join('MLP','xY_val_T_data_{}_T_seg_{}_N_hidden_{}.pt'.format(T_data,T_seg,N_hidden)))\n",
    "    torch.save(y_val,os.path.join('MLP','y_val_T_data_{}_T_seg_{}_N_hidden_{}.pt'.format(T_data,T_seg,N_hidden)))\n",
    "    \n",
    "    torch.save(MSE_Tr,os.path.join('MLP','MSE_Tr_T_data_{}_T_seg_{}_N_hidden_{}.pt'.format(T_data,T_seg,N_hidden)))\n",
    "    torch.save(MSE_Val,os.path.join('MLP','MSE_Val_T_data_{}_T_seg_{}_N_hidden_{}.pt'.format(T_data,T_seg,N_hidden)))\n",
    "    torch.save(MSE_Te,os.path.join('MLP','MSE_Te_T_data_{}_T_seg_{}_N_hidden_{}.pt'.format(T_data,T_seg,N_hidden)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84fe7c",
   "metadata": {},
   "source": [
    "Run the ESN hyperparameters from the manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ddbd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "Iteration number:  0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "T_datax=[50,100,150,200,250,500,1000,2000]\n",
    "N_ESNx=np.int32(np.arange(1,41)*10) ## 40 different ESN size, The training should be increadibly quick\n",
    "N_train=20000\n",
    "N_checkpoint=19999\n",
    "params = []\n",
    "for T_data in T_datax:\n",
    "    for N_ESN in N_ESNx:\n",
    "        \n",
    "        params.append([T_data,N_ESN])\n",
    "import sys\n",
    "print(len(params))\n",
    "val_prc=0.1\n",
    "\n",
    "for i in range(len(params)):\n",
    "    param = params[i]\n",
    "        \n",
    "    T_data=param[0]\n",
    "    N_ESN = param[1]\n",
    "        \n",
    "\n",
    "\n",
    "    Data=Data_Manager(\"MACKEY_manuscript\",T_data)\n",
    "    #N_ESN=500 ## Number of nodes in the ESN\n",
    "\n",
    "    N_in=1          ## Input dimensionality\n",
    "    N_av=10         ## Average number od connection for an ESN node\n",
    "    alpha=0.9       ## Leakage term for the ESN node\n",
    "    rho=0.99        ## Spectral radius\n",
    "    gamma=0.15      ## Input scaling \n",
    "    T_seg=0\n",
    "    Data.Init_ESN(N_ESN, N_in, N_av, alpha, rho, gamma)\n",
    "    Data.ESN_Process()\n",
    "    Data.Splitting(val_prc)\n",
    "\n",
    "    F_Ns=torch.tensor([N_ESN,Data.Y_tr.size()[1]]) ## Definition of a simple read-out to be trained\n",
    "\n",
    "    eta=0.0001 ## Learning rate\n",
    "    weight_decay=0 ## Learning rate of the L2 penalty term\n",
    "    model=Model_Learning(F_Ns, eta, weight_decay)\n",
    "\n",
    "    T_seq=1\n",
    "    \n",
    "    N_train=20000\n",
    "    N_checkpoint=19999\n",
    "    \n",
    "    N_check=int(np.ceil(N_train/N_checkpoint))\n",
    "    ind_help=0\n",
    "\n",
    "    N_chunks=1\n",
    "\n",
    "    MSE_Train=torch.zeros([N_train])\n",
    "\n",
    "    MSE_Tr=torch.zeros([N_check])\n",
    "    MSE_Val=torch.zeros([N_check])\n",
    "    MSE_Te=torch.zeros([N_check])\n",
    "\n",
    "    t0s=torch.tensor(0.)\n",
    "    batch_size=20\n",
    "\n",
    "    for k in range(N_train):\n",
    "\n",
    "        X_b, Y_b=Data.Batch(batch_size, T_seq)\n",
    "        #print(X_b.shape,Y_b.shape)\n",
    "        if model.N_ODE:\n",
    "\n",
    "            var_help=X_b.clone()\n",
    "            X_b=var_help[:,:,0:-1].clone()\n",
    "            X_b=torch.concat([X_b,X_b],1)\n",
    "\n",
    "            Y_b=var_help[:,:,1:]\n",
    "\n",
    "        err,_=model.forward(X_b,Y_b,t0s)\n",
    "        MSE_Train[k]=err.detach()\n",
    "\n",
    "        if k%N_checkpoint==0: \n",
    "\n",
    "\n",
    "            if k>0:\n",
    "\n",
    "                mse_mean=torch.mean(MSE_Train[k-N_checkpoint:k])\n",
    "\n",
    "                MSE_Tr[ind_help]=mse_mean\n",
    "\n",
    "            else:\n",
    "\n",
    "                MSE_Tr[ind_help]=MSE_Train[k]\n",
    "\n",
    "\n",
    "            ## VALIDATING ##\n",
    "            #############\n",
    "\n",
    "            X_val,Y_val=Data.Testing()\n",
    "\n",
    "            if model.N_ODE:\n",
    "\n",
    "                var_help=X_val.clone()\n",
    "                X_val=var_help[:,:,0:-1].clone()\n",
    "                X_val=torch.concat([X_val,X_val],1)\n",
    "\n",
    "                Y_val=var_help[:,:,1:]\n",
    "\n",
    "            err_, y_val=model.Seqforward(X_val,Y_val,t0s)\n",
    "\n",
    "            MSE_Val[ind_help]=err_.detach()\n",
    "\n",
    "            ## TESTING ##\n",
    "            #############\n",
    "\n",
    "            X_te,Y_te=Data.Testing(False)\n",
    "\n",
    "            if model.N_ODE:\n",
    "\n",
    "                var_help=X_te.clone()\n",
    "                X_te=var_help[:,:,0:-1].clone()\n",
    "                X_te=torch.concat([X_te,X_te],1)\n",
    "\n",
    "                Y_te=var_help[:,:,1:]\n",
    "\n",
    "            err_, y_te=model.Seqforward(X_te,Y_te,t0s)\n",
    "\n",
    "            MSE_Te[ind_help]=err_.detach()\n",
    "\n",
    "            Nx_plot=3\n",
    "            Ny_plot=3\n",
    "\n",
    "            fig, axs = plt.subplots(Nx_plot, Ny_plot,figsize=(20,10))\n",
    "\n",
    "            print('Iteration number: ', k)\n",
    "            for l in range(Nx_plot):\n",
    "\n",
    "                for m in range(Ny_plot):\n",
    "\n",
    "                    t_pred=l*Nx_plot+m\n",
    "                    axs[l,m].plot(y_val.detach().to('cpu')[0,t_pred,:],'black')\n",
    "                    #print(y_val.shape)\n",
    "                    axs[l,m].plot(Y_val.detach().to('cpu')[0,t_pred,:],'red')\n",
    "\n",
    "                    axs[l,m].legend(['Prediction','Target'])\n",
    "                    #tit=\n",
    "                    axs[l,m].title.set_text('Delay: '+str(t_pred))\n",
    "\n",
    "\n",
    "            plt.savefig(os.path.join('ESN','plot_T_data_{}_N_ESN_{}.png'.format(T_data,N_ESN)))\n",
    "\n",
    "            print('Errors: ', MSE_Tr[ind_help], MSE_Val[ind_help] , MSE_Te[ind_help])\n",
    "\n",
    "            ind_help=ind_help+1\n",
    "\n",
    "    torch.save(y_te,os.path.join('ESN','y_te_T_data_{}_N_ESN_{}.pt'.format(T_data,N_ESN)))\n",
    "    torch.save(Y_te,os.path.join('ESN','xY_te_T_data_{}_N_ESN_{}.pt'.format(T_data,N_ESN)))\n",
    "    torch.save(y_val,os.path.join('ESN','y_val_T_data_{}_N_ESN_{}.pt'.format(T_data,N_ESN)))\n",
    "    torch.save(Y_val,os.path.join('ESN','xY_val_T_data_{}_N_ESN_{}.pt'.format(T_data,N_ESN)))\n",
    "    torch.save(MSE_Tr,os.path.join('ESN','MSE_Tr_T_data_{}_N_ESN_{}.pt'.format(T_data,N_ESN)))\n",
    "    torch.save(MSE_Val,os.path.join('ESN','MSE_Val_T_data_{}_N_ESN_{}.pt'.format(T_data,N_ESN)))\n",
    "    torch.save(MSE_Te,os.path.join('ESN','MSE_Te_T_data_{}_N_ESN_{}.pt'.format(T_data,N_ESN)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cdb6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9965c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
