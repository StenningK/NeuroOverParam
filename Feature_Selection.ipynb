{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b1d288",
   "metadata": {},
   "source": [
    "## Benchmark with Correlation\n",
    "\n",
    "The following simulations are based on the class DATA that can be found in Util.py.\n",
    "\n",
    "The cell below performs an optimisation process using the method Benchmark_Correlation, which \n",
    "\n",
    "1. Computes an autocorrelation structure of the reservoir response \n",
    "\n",
    "2. Selects the best hyperparmaters couple $\\theta$ and $\\lambda$. $\\theta$ is a threshold to perform feature selection from the \n",
    "autocorrelation structure. The reservoir responses that are correlated more than the selected value of $\\theta$ are discarded, and the remaining responses are used for optimisation and testing. $\\lambda$ is multiplicative factor of the penalty term for ridge-regression. Both these hyperparamters can help avoiding overfitting, and thus are optimised together through a grid search over the $(\\theta, \\lambda)$ space. \n",
    "\n",
    "Given the limited amount of data available. The Benchmark_Correlation method splits the dataset in the following way.\n",
    "\n",
    "1. First, a percantage $p_{te}$ of data is selected for testing.\n",
    "\n",
    "2. Then, the method performs ten-cross validation on the remaining data and selects the $(\\theta, \\lambda)$ that corresponds to the highest average performance (minimum error) on the validation sets. The testing performance is finally computed using such optimal $(\\theta, \\lambda)$ on the unseen test set selected in 1.\n",
    "\n",
    "This procedure is repeated $1/p_{te}$ times with different test sets to be certain that the results were not due to a lucky split.\n",
    "\n",
    "\n",
    "In the following, we repeat the procedure for different reservoir architectures.\n",
    "To select a specific reservoir architecture to train and evaluate, it is sufficient to provide the files numbers to be used.\n",
    "Below this is defined in the 'option' variable.\n",
    "\n",
    "To train on a specific task, you can provide the task name to the class Data. Below, this is done in the 'Task' variable.\n",
    "Valid Tasks names can be:\n",
    "\n",
    "- Narma. Performs Narma 1 to 15 on the Mackey-Glass dataset. \n",
    "- SINE. Performs different sine waves transformations.\n",
    "- MC. Computes the memory capacity of the selcted architecture from the Mackey-Glass dataset. When performing this task, use the method Measure_MC and not Benchmark_Correlation. See the notebook Metrics for an example of this.\n",
    "- NL. Computes the non-linearity of the architecture considered. When performing this task, use the method Measure_NL and not Benchmark_Correlation. See the notebook Metrics for an example of this.\n",
    "- Prediction_Narma. The method performs a Narma 7 on the future instances of the Mackey-Glass.\n",
    "- If none of the above is pecified, the method performs future prediction on the Mackey-Glass dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4acda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the packages and define functions\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Util import *\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "\n",
    "# This function loads all the data from the defined folder. \n",
    "# Datalen is the length of the data to analyse (default 250)\n",
    "def load_data(folder, datalen = 250):\n",
    "    array_init=False\n",
    "    \n",
    "    ## Loop through data files in each folder\n",
    "    for file in os.listdir(folder):\n",
    "        if '.npy' in file:\n",
    "            \n",
    "            # Load the data\n",
    "            data=np.load(os.path.join(folder,file),allow_pickle=True)\n",
    "            \n",
    "            #Seperate output states and input fields\n",
    "            states = data[:datalen,:-1]\n",
    "            input_ = data[:datalen,-1].reshape(-1,1)\n",
    "            \n",
    "            # Initialise the array\n",
    "            if array_init==False:\n",
    "                data_all = states\n",
    "                input_all = input_\n",
    "\n",
    "\n",
    "\n",
    "                array_init = True\n",
    "            # Concatenate the inputs and outputs\n",
    "            else:\n",
    "                if len(data)>(datalen-1):\n",
    "                    data_all=np.concatenate([data_all[:datalen],data[:datalen]],axis=1)\n",
    "                    input_all=np.concatenate([input_all[:datalen],input_[:datalen]],axis=1)\n",
    "                else:\n",
    "                    print('File has less data than required - ', file)\n",
    "    return data_all, input_all\n",
    "                    \n",
    "# Define an arbitrary Mackley Glass time series\n",
    "def Mackey_Def(T_data,b=0.2,a=.1,tau=17,delta=10):\n",
    "    \n",
    "    N_pred=20\n",
    "    burn_in=20\n",
    "\n",
    "    T_gen=2*(T_data+burn_in+N_pred)\n",
    "\n",
    "    s=torch.zeros([T_gen])\n",
    "\n",
    "    s[0:tau]=1.1*torch.rand([tau])+0.2\n",
    "\n",
    "    for t in range(tau,T_gen):\n",
    "\n",
    "        s[t]=s[t-1]+b*s[t-tau]/(1+s[t-tau]**delta)-a*s[t-1]\n",
    "    \n",
    "    S=s[np.arange(0,np.floor(T_gen/2))*2]\n",
    "    \n",
    "    Signal=S[burn_in:-N_pred]\n",
    "    \n",
    "    Y=torch.zeros([Signal.size()[0],N_pred])\n",
    "\n",
    "    for n in range(0,N_pred):\n",
    "\n",
    "        Y[:,n]=S[burn_in+n:-N_pred+n]\n",
    "        \n",
    "    return Signal, Y\n",
    "\n",
    "# Load the Mackey Glass series used in the manuscript\n",
    "def Mackey_Manuscript(T_data):\n",
    "    MG_paper = np.load('mackey_glass_t17.npy')\n",
    "    MG_actual=[]\n",
    "    for i in range(T_data):\n",
    "        MG_actual.append(MG_paper[2*i])\n",
    "    return MG_actual\n",
    "\n",
    "# Define the sine transformation tasks. Default period is 30\n",
    "def Sine_Tasks(T_data,period = 30):\n",
    "    \n",
    "    x = np.arange(0,T_data)\n",
    "    \n",
    "    all_targets = []\n",
    "    target_names = []\n",
    "    \n",
    "    ## Get sine variations\n",
    "    sinx = np.sin(x*2*3.1415/(period))\n",
    "    all_targets.append(sinx)\n",
    "    target_names.append('sinx')\n",
    "    sinp5x = np.sin(x*2*3.1415/(2*period))\n",
    "    all_targets.append(sinp5x)\n",
    "    target_names.append('sinp5x')\n",
    "    sin2x = np.sin(x*2*3.1415/(0.5*period))\n",
    "    all_targets.append(sin2x)\n",
    "    target_names.append('sin2x')\n",
    "    sin3x = np.sin(x*2*3.1415/((1/3)*period))\n",
    "    all_targets.append(sin3x)\n",
    "    target_names.append('sin3x')\n",
    "    sin_squared = sinx**2\n",
    "    all_targets.append(sin_squared)\n",
    "    target_names.append('sin_squared')\n",
    "    sin_cubed = sinx**3\n",
    "    all_targets.append(sin_cubed)\n",
    "    target_names.append('sin_cubed')\n",
    "    \n",
    "    #Get cos variations\n",
    "    cosx = np.cos(x*2*3.1415/(period))\n",
    "    all_targets.append(cosx)\n",
    "    target_names.append('cosx')\n",
    "    cosp5x = np.cos(x*2*3.1415/(2*period))\n",
    "    all_targets.append(cosp5x)\n",
    "    target_names.append('cosp5x')\n",
    "    cos2x = np.cos(x*2*3.1415/(0.5*period))\n",
    "    all_targets.append(cos2x)\n",
    "    target_names.append('cos2x')\n",
    "    cos3x= np.cos(x*2*3.1415/((1/3)*period))\n",
    "    all_targets.append(cos3x)\n",
    "    target_names.append('cos3x')\n",
    "    \n",
    "    #Get Saw variations\n",
    "    sawx = signal.sawtooth(x*2*3.1415/(period))\n",
    "    all_targets.append(sawx)\n",
    "    target_names.append('sawx')\n",
    "    saw2x = signal.sawtooth(x*2*3.1415/(0.5*period))\n",
    "    all_targets.append(saw2x)\n",
    "    target_names.append('saw2x')\n",
    "    \n",
    "    ## Scale all the above functions\n",
    "    for i in range(len(all_targets)):\n",
    "        all_targets[i] = (all_targets[i]-np.min(all_targets[i]))/(np.max(all_targets[i])-np.min(all_targets[i]))\n",
    "    \n",
    "    ## Append the tasks and names to a final list\n",
    "    final_targets = []\n",
    "    final_names = []\n",
    "    for i in range(len(all_targets)):\n",
    "        final_targets.append(all_targets[i])\n",
    "        final_names.append(target_names[i])\n",
    "    \n",
    "    ## Add all of the base tasks previously defined\n",
    "    for i in range(len(all_targets)):\n",
    "        for j in range(len(all_targets)):\n",
    "            if j>=i:\n",
    "                new = (all_targets[i]+all_targets[j])\n",
    "                new = (new-np.min(new))/(np.max(new)-np.min(new))\n",
    "                final_targets.append(new)\n",
    "                final_names.append(target_names[i]+'+'+target_names[j])\n",
    "\n",
    "    ## Multiply all of the base tasks previously defined\n",
    "    for i in range(len(all_targets)):\n",
    "        for j in range(len(all_targets)):\n",
    "            if j>=i:\n",
    "                new = (all_targets[i]*all_targets[j])\n",
    "                new = (new-np.min(new))/(np.max(new)-np.min(new))\n",
    "                final_targets.append(new)\n",
    "                final_names.append(target_names[i]+'*'+target_names[j])\n",
    "\n",
    "    return final_targets, final_names\n",
    "\n",
    "# Functions for defining the NARMA transform tasks.\n",
    "def NARMA(Y,n_back,T_data):\n",
    "                \n",
    "                \n",
    "    \n",
    "\n",
    "    signal=np.copy(Y);\n",
    "    Y=np.zeros([T_data,n_back])    \n",
    "\n",
    "    start=15\n",
    "\n",
    "    for n in range(n_back):\n",
    "\n",
    "        Y[:,n]=Narma(signal[:T_data],n,start)\n",
    "    return Y\n",
    "        \n",
    "def Narma(s, step, start):\n",
    "\n",
    "    \n",
    "    T=np.shape(s)[0]\n",
    "    y=torch.zeros([T])\n",
    "    \n",
    "    alpha=0.3\n",
    "    beta=0.01\n",
    "    gamma=2\n",
    "    delta=0.1\n",
    "    \n",
    "    for t in range(step,T):\n",
    "        \n",
    "        y[t]=alpha*y[t-1]+beta*y[t-1]*torch.sum(y[t-step:t])+gamma*s[t-step]*s[t-1]+delta\n",
    "        \n",
    "            \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a40c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "from scipy import io\n",
    "from Util import *\n",
    "#reload(Util)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')                       \n",
    "## We can ignore warnings. INases Ridge-Regression will \n",
    "## complain about matrix inversion. However, we are using different splits \n",
    "## to select best hyperparameters, where training is well-defined.\n",
    "\n",
    "\n",
    "datafolder=r'Data\\Mackey_Glass\\Single\\MS' ## The data folder to perform the predictions on. \n",
    "\n",
    "\n",
    "ths=np.array([0.999, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92]) # Values of theta (Hyperparameter) to be optimised (grid-search, explained above).\n",
    "\n",
    "len_data = 250\n",
    "data, inputs = load_data(datafolder,len_data)\n",
    "print('Data shape = ',data.shape)\n",
    "\n",
    "targetname = 'MG_Predict' # Select NARMA / MG_predict / SINE\n",
    "\n",
    "## Mackey-Glass future prediction\n",
    "MG = Mackey_Manuscript(1000)\n",
    "MG = (MG-np.min(MG))/(np.max(MG)-np.min(MG))\n",
    "\n",
    "if targetname=='MG_Predict':\n",
    "# Define the targets - MG future prediction\n",
    "    delays = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "    targets = np.zeros((len(delays),len_data))\n",
    "    for i in range(len(delays)):\n",
    "        targets[i] = MG[delays[i]:len_data+delays[i]]\n",
    "\n",
    "if targetname=='NARMA':   \n",
    "    # Define the targets - MG NARMA\n",
    "    n_narma = 15\n",
    "    targets = NARMA(MG,n_narma,len_data)\n",
    "    \n",
    "if targetname=='NARMA_pred':   \n",
    "    # Define the targets - MG NARMA predict\n",
    "    delays = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "    targets_temp = np.zeros((len(delays),len_data))\n",
    "    targets= np.zeros((len(delays),len_data))\n",
    "    start=15\n",
    "    for i in range(len(delays)):\n",
    "        targets_temp[i] = MG[delays[i]:len_data+delays[i]]\n",
    "    n_narma = 7\n",
    "    for i in range(len(delays)):\n",
    "        targets[i] = Narma(targets_temp[i],n_narma,start).T\n",
    "\n",
    "if targetname =='SINE':\n",
    "    targets, names = Sine_Tasks(250,30)\n",
    "\n",
    "\n",
    "MSE_Tr1=[]\n",
    "MSE_Val1=[]\n",
    "MSE_Te1=[]\n",
    "\n",
    "Feats1=[]\n",
    "Best_hyper1=[]\n",
    "Z_val1=[]\n",
    "Z_te1=[]\n",
    "\n",
    "# Percentage split for the test set\n",
    "p_te=0.2\n",
    "# The number of outer cross validations is 1/p_te \n",
    "\n",
    "## Initialise the class with the targets, data to be trialled and percentage split for train\n",
    "Data=DATA_CLEAN(targets.T,data,p_te)\n",
    "\n",
    "# Do an initial split of the training data to initialise the arrays\n",
    "Data.CrossVal(3,1)\n",
    "\n",
    "# Do an initial correlation analysis\n",
    "Data.CORR()\n",
    "\n",
    "'''\n",
    "This function does the optimisation and returns the following data.\n",
    "MSE_tr / MSE_val / MSE_te : a matrix with the Tr, Val and Te MSE's for each outer loop of cross validation\n",
    "RM : The features which are removed for each outer validation\n",
    "Best Hyper : The best theta, bets alpha and number of features remaining for each validation\n",
    "Z_val / Z_te : Matrix with size (1/p_te, len_data, n_tasks, 2) containing the predictions for the validation \n",
    "                and test for every task and outer loop split\n",
    "'''\n",
    "MSE_tr, MSE_val, MSE_te, RM, Best_hyper, Z_val, Z_te=Data.Benchmark_Correlation(ths)\n",
    "\n",
    "MSE_Tr1.append(MSE_tr)\n",
    "MSE_Val1.append(MSE_val)\n",
    "MSE_Te1.append(MSE_te)\n",
    "\n",
    "Feats1.append(RM)\n",
    "Best_hyper1.append(Best_hyper)\n",
    "Z_val1.append(Z_val)\n",
    "Z_te1.append(Z_te)\n",
    "\n",
    "fname = targetname+'_all'\n",
    "savdir = os.path.join(datafolder,'Feature_Selection')\n",
    "if os.path.isdir(savdir) is False:\n",
    "    os.mkdir(savdir)\n",
    "\n",
    "## The results are saved in MATLAB files. To recreate the figures of the paper, refer to the analysis and figure plotting codes in the GitHub description\n",
    "## The results will be saved within a new folder inside the data folder named 'Feature_Selection'\n",
    "\n",
    "io.savemat(os.path.join(savdir,'Corr_MSETe'+fname+'.mat'),{\"array\": np.float32(MSE_Te1)})\n",
    "io.savemat(os.path.join(savdir,'Corr_MSEVal'+fname+'.mat'),{\"array\": np.float32(MSE_Val1)})\n",
    "io.savemat(os.path.join(savdir,'Corr_MSETr'+fname+'.mat'),{\"array\": np.float32(MSE_Tr1)})\n",
    "io.savemat(os.path.join(savdir,'Corr_ZTe'+fname+'.mat'),{\"array\": np.float32(Z_te1)})\n",
    "io.savemat(os.path.join(savdir,'Corr_Zval'+fname+'.mat'),{\"array\": np.float32(Z_val1)})\n",
    "for i in range(len(Feats1)):\n",
    "    io.savemat(os.path.join(savdir,str(i)+'Corr_Feats2'+fname+'.mat'),{\"array\": Feats1[i]})\n",
    "io.savemat(os.path.join(savdir,'Corr_Best_hyper2'+fname+'.mat'),{\"array\": np.float32(Best_hyper1)})\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55230056",
   "metadata": {},
   "source": [
    "## Evolutionary algorithm, fine-tuning feature selection\n",
    "\n",
    "The cell below exploits again the class DATA, but to perform an evolutionary algorithm to fine-tune the feature selection.\n",
    "It is necessary to run one of the cell above with the Benchmark_Correlation method before running the following.\n",
    "Indeed, the evolutionary algorithm is initialised from the features found after optimisation of the hyperparameter $\\theta$.\n",
    "Thus, the method Evolutionary needs a starting Mask specifying which features to use at the beginning and the best hyperparameters $(\\theta, \\lambda)$ for each different split.\n",
    "The cell automatically saves the results. Please, change the names accordingly to what you are running.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d340b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index=0\n",
    "\n",
    "MSE_trials=[]\n",
    "Z_val_trials = []\n",
    "Z_te_trials = []\n",
    "\n",
    "# Get the feature mask\n",
    "Mask=np.array(Feats1[index])\n",
    "\n",
    "# Use the first feature mask\n",
    "Mask2=np.copy(Mask[0,:])\n",
    "\n",
    "# Get indicies of removed features\n",
    "RM=np.where(Mask2==1)\n",
    "\n",
    "#Initialise the data again\n",
    "Data=DATA_CLEAN(targets.T,data,p_te)\n",
    "\n",
    "# Get the best alphas\n",
    "alphas=Best_hyper1[index][:,1]\n",
    "\n",
    "# Mutation percentage a function of the number of features\n",
    "p_mutation=1/np.shape(Mask)[1]\n",
    "N_iteration=5\n",
    "\n",
    "#Loop through the number of iteration\n",
    "for i in range(N_iteration):\n",
    "    print('Iteration', i)\n",
    "    MSE, MSE_bench, Z_val, Z_te=Data.Evolutionary(Mask, p_mutation, N_iteration, alphas)\n",
    "\n",
    "    MSE_trials.append(MSE)\n",
    "    Z_val_trials.append(Z_val)\n",
    "    Z_te_trials.append(Z_te)\n",
    "\n",
    "\n",
    "io.savemat(os.path.join(savdir,'Evol_MSE_trials'+fname+'.mat'),{\"array\": np.float32(MSE_trials)})\n",
    "io.savemat(os.path.join(savdir,'Evol_Z_te'+fname+'.mat'),{\"array\": np.float32(Z_te_trials)})\n",
    "io.savemat(os.path.join(savdir,'Evol_Z_val'+fname+'.mat'),{\"array\": np.float32(Z_val_trials)})\n",
    "io.savemat(os.path.join(savdir,'Evol_RM'+fname+'.mat'),{\"array\": np.float32(RM_trials)})\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
