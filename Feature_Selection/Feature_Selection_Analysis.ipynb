{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Util import *\n",
    "import torch\n",
    "from scipy import io\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load the raw files\n",
    "def load_data(folder, datalen):\n",
    "    array_init=False\n",
    "    \n",
    "    ## Loop through data files in each folder\n",
    "    for file in os.listdir(folder):\n",
    "        if '.npy' in file:\n",
    "            \n",
    "            # Load the data\n",
    "            data=np.load(os.path.join(folder,file),allow_pickle=True)\n",
    "            \n",
    "            #Seperate states and input fields\n",
    "            states = data[:datalen,1:]\n",
    "            input_ = data[:datalen,0].reshape(-1,1)\n",
    "            \n",
    "            # Initialise the array for all states\n",
    "            if array_init==False:\n",
    "                data_all = states\n",
    "                input_all = input_\n",
    "\n",
    "\n",
    "\n",
    "                array_init = True\n",
    "            else:\n",
    "                if len(data)>(datalen-1):\n",
    "                    data_all=np.concatenate([data_all[:datalen],data[:datalen]],axis=1)\n",
    "                    input_all=np.concatenate([input_all[:datalen],input_[:datalen]],axis=1)\n",
    "                else:\n",
    "                    print('File has less data than required - ', file)\n",
    "    return data_all, input_all\n",
    "# Load the Mackey Glass series from the manuscript\n",
    "def Mackey_Manuscript(T_data):\n",
    "    MG_paper = np.load('mackey_glass_t17.npy')\n",
    "    MG_actual=[]\n",
    "    for i in range(T_data):\n",
    "        MG_actual.append(MG_paper[2*i])\n",
    "    return MG_actual\n",
    "# Define arbitrary Mackey Glass series      \n",
    "def Mackey_Def(T_data,b=0.2,a=.1,tau=17,delta=10):\n",
    "    \n",
    "    N_pred=20\n",
    "    burn_in=20\n",
    "\n",
    "    T_gen=2*(T_data+burn_in+N_pred)\n",
    "\n",
    "    s=torch.zeros([T_gen])\n",
    "\n",
    "    s[0:tau]=1.1*torch.rand([tau])+0.2\n",
    "\n",
    "    for t in range(tau,T_gen):\n",
    "\n",
    "        s[t]=s[t-1]+b*s[t-tau]/(1+s[t-tau]**delta)-a*s[t-1]\n",
    "    \n",
    "    S=s[np.arange(0,np.floor(T_gen/2))*2]\n",
    "    \n",
    "    Signal=S[burn_in:-N_pred]\n",
    "    \n",
    "    Y=torch.zeros([Signal.size()[0],N_pred])\n",
    "\n",
    "    for n in range(0,N_pred):\n",
    "\n",
    "        Y[:,n]=S[burn_in+n:-N_pred+n]\n",
    "        \n",
    "    return Signal, Y\n",
    "\n",
    "# Define the sine tasks\n",
    "def Sine_Tasks(T_data,period = 30):\n",
    "    \n",
    "    x = np.arange(0,T_data)\n",
    "    \n",
    "    all_targets = []\n",
    "    target_names = []\n",
    "    \n",
    "    ## Get sine variations\n",
    "    sinx = np.sin(x*2*3.1415/(period))\n",
    "    all_targets.append(sinx)\n",
    "    target_names.append('sinx')\n",
    "    sinp5x = np.sin(x*2*3.1415/(2*period))\n",
    "    all_targets.append(sinp5x)\n",
    "    target_names.append('sinp5x')\n",
    "    sin2x = np.sin(x*2*3.1415/(0.5*period))\n",
    "    all_targets.append(sin2x)\n",
    "    target_names.append('sin2x')\n",
    "    sin3x = np.sin(x*2*3.1415/((1/3)*period))\n",
    "    all_targets.append(sin3x)\n",
    "    target_names.append('sin3x')\n",
    "    sin_squared = sinx**2\n",
    "    all_targets.append(sin_squared)\n",
    "    target_names.append('sin_squared')\n",
    "    sin_cubed = sinx**3\n",
    "    all_targets.append(sin_cubed)\n",
    "    target_names.append('sin_cubed')\n",
    "    \n",
    "    #Get cos variations\n",
    "    cosx = np.cos(x*2*3.1415/(period))\n",
    "    all_targets.append(cosx)\n",
    "    target_names.append('cosx')\n",
    "    cosp5x = np.cos(x*2*3.1415/(2*period))\n",
    "    all_targets.append(cosp5x)\n",
    "    target_names.append('cosp5x')\n",
    "    cos2x = np.cos(x*2*3.1415/(0.5*period))\n",
    "    all_targets.append(cos2x)\n",
    "    target_names.append('cos2x')\n",
    "    cos3x= np.cos(x*2*3.1415/((1/3)*period))\n",
    "    all_targets.append(cos3x)\n",
    "    target_names.append('cos3x')\n",
    "    \n",
    "    #Get Saw variations\n",
    "    sawx = signal.sawtooth(x*2*3.1415/(period))\n",
    "    all_targets.append(sawx)\n",
    "    target_names.append('sawx')\n",
    "    saw2x = signal.sawtooth(x*2*3.1415/(0.5*period))\n",
    "    all_targets.append(saw2x)\n",
    "    target_names.append('saw2x')\n",
    "    \n",
    "    ## Scale all the above functions\n",
    "    for i in range(len(all_targets)):\n",
    "        all_targets[i] = (all_targets[i]-np.min(all_targets[i]))/(np.max(all_targets[i])-np.min(all_targets[i]))\n",
    "    \n",
    "    ## Append the tasks and names to a final list\n",
    "    final_targets = []\n",
    "    final_names = []\n",
    "    for i in range(len(all_targets)):\n",
    "        final_targets.append(all_targets[i])\n",
    "        final_names.append(target_names[i])\n",
    "    \n",
    "    ## Add all of the base tasks previously defined\n",
    "    for i in range(len(all_targets)):\n",
    "        for j in range(len(all_targets)):\n",
    "            if j>=i:\n",
    "                new = (all_targets[i]+all_targets[j])\n",
    "                new = (new-np.min(new))/(np.max(new)-np.min(new))\n",
    "                final_targets.append(new)\n",
    "                final_names.append(target_names[i]+'+'+target_names[j])\n",
    "\n",
    "    ## Multiply all of the base tasks previously defined\n",
    "    for i in range(len(all_targets)):\n",
    "        for j in range(len(all_targets)):\n",
    "            if j>=i:\n",
    "                new = (all_targets[i]*all_targets[j])\n",
    "                new = (new-np.min(new))/(np.max(new)-np.min(new))\n",
    "                final_targets.append(new)\n",
    "                final_names.append(target_names[i]+'*'+target_names[j])\n",
    "\n",
    "    return final_targets, final_names\n",
    "\n",
    "# Define the NARMA transforms\n",
    "def NARMA(Y,n_back,T_data):\n",
    "                \n",
    "                \n",
    "    \n",
    "\n",
    "    signal=np.copy(Y);\n",
    "    Y=np.zeros([T_data,n_back])    \n",
    "\n",
    "    start=15\n",
    "\n",
    "    for n in range(n_back):\n",
    "\n",
    "        Y[:,n]=Narma(signal[:T_data],n,start)\n",
    "    return Y\n",
    "        \n",
    "def Narma(s, step, start):\n",
    "\n",
    "    \n",
    "    T=np.shape(s)[0]\n",
    "    y=torch.zeros([T])\n",
    "    \n",
    "    alpha=0.3\n",
    "    beta=0.01\n",
    "    gamma=2\n",
    "    delta=0.1\n",
    "    \n",
    "    for t in range(step,T):\n",
    "        \n",
    "        y[t]=alpha*y[t-1]+beta*y[t-1]*torch.sum(y[t-step:t])+gamma*s[t-step]*s[t-1]+delta\n",
    "        \n",
    "            \n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to analyse the predictions from the feature selection algorithm\n",
    "\n",
    "## Function to \n",
    "def full_analysis(datafolder,targetname):\n",
    "    \n",
    "    fname = targetname+'_all'\n",
    "    \n",
    "    savdir = os.path.join(datafolder,'Feature_Selection')\n",
    "    \n",
    "    if os.path.isdir(savdir) is False:\n",
    "        os.mkdir(savdir)\n",
    "\n",
    "    ## Load the MSEs and features from the correlation step\n",
    "    MSE_Te1 = io.loadmat(os.path.join(savdir,'Corr_MSETe'+fname+'.mat'))['array']\n",
    "    Feats=[]\n",
    "    for i in range(1):\n",
    "        \n",
    "        Feats1=io.loadmat(os.path.join(savdir,str(i)+'Corr_Feats2'+fname+'.mat'))['array']\n",
    "        Feats.append(Feats1)\n",
    "    \n",
    "\n",
    "    ## Calculate the mean and standard deviations from the correlation step\n",
    "    means_Corr = np.mean(np.mean(np.array(MSE_Te1),axis=0),0)\n",
    "    stds_Corr = np.std(np.mean(np.array(MSE_Te1),axis=1),0)\n",
    "    \n",
    "\n",
    "    ## Load the MSE and features from the evolutionary step\n",
    "    MSE_trials = io.loadmat(os.path.join(savdir,'Evol_MSE_trials'+fname+'.mat'))['array']\n",
    "    RM = []\n",
    "    for i in range(5):\n",
    "        RM.append(io.loadmat(os.path.join(savdir,'Evol_RM'+fname+str(i)+'.mat'))['array'])\n",
    "    \n",
    "    # Calculate the mean and standard deviations from the evolutionary step\n",
    "    means_evol = np.mean(np.mean(np.array(MSE_trials),axis=0),0)\n",
    "    stds_evol = np.std(np.mean(np.array(MSE_trials),axis=1),0)\n",
    "    ## Returns the means, standard deviations and features from correlation and evolutionary steps\n",
    "    return means_Corr, stds_Corr, means_evol, stds_evol, Feats, RM\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.path.split(os.getcwd())[0]\n",
    "netfold = os.path.join(base,r'Data\\Mackey_Glass\\PNN\\All') # Select the datafolder to analyse\n",
    "data, inputs = load_data(netfold,250)\n",
    "\n",
    "means_Corr, stds_Corr, means_evol, stds_evol, Feats_all, RM_all = full_analysis(netfold,'MG_predict')\n",
    "\n",
    "# Sort the feature data to give the total number of features used.\n",
    "all_lens_evol=np.zeros((1,5))\n",
    "for i in range(5):\n",
    "    RM = RM_all[i][0]\n",
    "    num_features = data.shape[1]-len(RM)\n",
    "    all_lens_evol[0][i]=num_features\n",
    "all_lens_corr=np.zeros((1,5))\n",
    "for i in range(5):\n",
    "    num_features = len(np.where(Feats_all[0][i]==0)[0])\n",
    "    all_lens_corr[0][i] = num_features\n",
    "    \n",
    "results = np.array([means_Corr,stds_Corr,means_evol,stds_evol])\n",
    "print(all_lens_corr,all_lens_evol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "x = np.arange(0,len(results[2]))\n",
    "\n",
    "xx=np.arange(0,max(x),0.05)#:max(x)\n",
    "yy_up=sp.interpolate.interp1d(x, results[2]-2*results[3], kind='cubic')(xx)\n",
    "yy_down=sp.interpolate.interp1d(x, results[2]+2*results[3], kind='cubic')(xx)\n",
    "yy = sp.interpolate.interp1d(x, results[2], kind='cubic')(xx)\n",
    "#print(results_Gen[0])\n",
    "ax.fill_between(xx,yy_down,yy_up,alpha=0.5)\n",
    "ax.scatter(x[:len(results[2])],results[2],s=13)\n",
    "\n",
    "ax.plot(xx[:len(yy)],yy)\n",
    "ax.set_xlabel('Future Step')\n",
    "ax.set_ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through all datafolders and save the response to a dictionary\n",
    "base = os.path.split(os.getcwd())[0]\n",
    "folder = os.path.join(base,r'Data\\Mackey_Glass')\n",
    "all_ = {}\n",
    "network_list = []\n",
    "task = 'NARMA_pred'\n",
    "for task in ['NARMA_pred','MG_predict','NARMA']:\n",
    "    for type_ in os.listdir(folder):\n",
    "        typefolder = os.path.join(folder,type_)\n",
    "        if os.path.isdir(typefolder):\n",
    "            for network in os.listdir(typefolder):\n",
    "                netfold = os.path.join(typefolder,network)\n",
    "                if os.path.isdir(netfold) and 'Clean_data' not in netfold and 'Individual' not in netfold:\n",
    "                    print(netfold)\n",
    "                    try:\n",
    "                        data, inputs = load_data(netfold,250)\n",
    "                        network_list.append(network)\n",
    "                        ## Returns the means and stds of the correlation and evolution steps. Feats_all is the features from the correlation step. RM_all is the features removed from the evolution step.\n",
    "                       \n",
    "                        means_Corr, stds_Corr, means_evol, stds_evol, Feats_all, RM_all = full_analysis(netfold,np.zeros(250),task,method,False)\n",
    "                        #print(means_evol)\n",
    "                        \n",
    "                        all_lens_evol=np.zeros((1,5))\n",
    "                        for i in range(5):\n",
    "                            RM = RM_all[i][0]\n",
    "                            num_features = data.shape[1]-len(RM)\n",
    "                            all_lens_evol[0][i]=num_features\n",
    "                        all_lens_corr=np.zeros((1,5))\n",
    "                        for i in range(5):\n",
    "                            num_features = len(np.where(Feats_all[0][i]==0)[0])\n",
    "                            all_lens_corr[0][i] = num_features\n",
    "                            \n",
    "\n",
    "                        \n",
    "                        result_Gen = np.array([means_Corr,stds_Corr,means_evol,stds_evol])\n",
    "                        all_[network] = [[result_Gen,all_lens_corr,all_lens_evol]]\n",
    "                    except:\n",
    "                        print('fail',network)\n",
    "                        pass\n",
    "    import pickle\n",
    "    # save dictionary to person_data.pkl file\n",
    "    with open(str(task)+'.pkl', 'wb') as fp:\n",
    "        pickle.dump(all_, fp)\n",
    "        print('dictionary saved successfully to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.path.split(os.getcwd())[0]\n",
    "folder = os.path.join(base,r'Data\\SINE')\n",
    "all_ = {}\n",
    "network_list = []\n",
    "task = 'SINE'\n",
    "for type_ in os.listdir(folder):\n",
    "    typefolder = os.path.join(folder,type_)\n",
    "    if os.path.isdir(typefolder):\n",
    "        for network in os.listdir(typefolder):\n",
    "            netfold = os.path.join(typefolder,network)\n",
    "            if os.path.isdir(netfold) and 'Clean_data' not in netfold:\n",
    "                \n",
    "                try:\n",
    "                    data, inputs = load_data(netfold,250)\n",
    "                    network_list.append(network)\n",
    "                    ## Returns the means and stds of the correlation and evolution steps. Feats_all is the features from the correlation step. RM_all is the features removed from the evolution step.\n",
    "                    \n",
    "                    \n",
    "                    means_Corr, stds_Corr, means_evol, stds_evol, Feats_all, RM_all = full_analysis(netfold,task)\n",
    "                    \n",
    "                    \n",
    "                    all_lens_evol=np.zeros((1,5))\n",
    "                    for i in range(5):\n",
    "                        RM = RM_all[i][0]\n",
    "                        num_features = data.shape[1]-len(RM)\n",
    "                        all_lens_evol[0][i]=num_features\n",
    "                    all_lens_corr=np.zeros((1,5))\n",
    "                    for i in range(5):\n",
    "                        \n",
    "                        num_features = len(np.where(Feats_all[0][i]==0)[0])\n",
    "                        all_lens_corr[0][i] = num_features\n",
    "                        \n",
    "\n",
    "                    \n",
    "                    result_Gen = np.array([means_Corr,stds_Corr,means_evol,stds_evol])\n",
    "                    all_[network] = [[result_Gen,all_lens_corr,all_lens_evol]]\n",
    "                except:\n",
    "                    print('fail',network)\n",
    "                    pass\n",
    "import pickle\n",
    "# save dictionary to person_data.pkl file\n",
    "with open(r'SINE.pkl', 'wb') as fp:\n",
    "    pickle.dump(all_, fp)\n",
    "    print('dictionary saved successfully to file')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
